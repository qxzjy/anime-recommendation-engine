{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "008d338d",
   "metadata": {},
   "source": [
    "# 1) Import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b231161f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from transformers import AutoModel  # NOT NEEDED FOR THE APP\n",
    "import ast\n",
    "\n",
    "\n",
    "import torch\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using {device} device\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7120f294",
   "metadata": {},
   "source": [
    "# 2) Import files "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b58987e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# profiles \n",
    "df_profiles = pd.read_csv(\"https://anime-recommendation-engine.s3.eu-west-3.amazonaws.com/data/profiles_clean.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ca7d988c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# synopsis embedding MiniLM\n",
    "df_MiniLM = pd.read_json('https://anime-recommendation-engine.s3.eu-west-3.amazonaws.com/data/synopsis_embedding.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c377e6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOT NEEDED FOR THE APP :  synopsis embedding Jina_1024   \n",
    "df_jina_1024= pd.read_json('https://anime-recommendation-engine.s3.eu-west-3.amazonaws.com/data/synopsis_embedding_jina_1024.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b8f422",
   "metadata": {},
   "source": [
    "# 3) preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "3ebd8f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_user(df):\n",
    "    df[\"favorites_anime\"] = df[\"favorites_anime\"].apply(ast.literal_eval)\n",
    "    df_favorites = df[[\"profile\", \"favorites_anime\"]].copy().explode(\"favorites_anime\")\n",
    "    df_favorites = df_favorites.dropna(subset=[\"favorites_anime\"])\n",
    "    df_favorites[\"favorites_anime\"] = df_favorites[\"favorites_anime\"].astype(\"int64\")\n",
    "\n",
    "    return df_favorites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "68e8c02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_favorites = preprocess_user(df_profiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e024cf",
   "metadata": {},
   "source": [
    "# MiniLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "cbb3bc35",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Model_MiniLM \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:348\u001b[0m, in \u001b[0;36mSentenceTransformer.__init__\u001b[0;34m(self, model_name_or_path, modules, device, prompts, default_prompt_name, similarity_fn_name, cache_folder, trust_remote_code, revision, local_files_only, token, use_auth_token, truncate_dim, model_kwargs, tokenizer_kwargs, config_kwargs, model_card_data, backend)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    346\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[0;32m--> 348\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_hpu_graph_enabled \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefault_prompt_name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompts:\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:1340\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1337\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1338\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m-> 1340\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 900 (1 times)]\u001b[0m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:900\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    899\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 900\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    903\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    904\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    905\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    910\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    911\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:927\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    923\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 927\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    928\u001b[0m p_should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    930\u001b[0m \u001b[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/torch/nn/modules/module.py:1326\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1320\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m   1321\u001b[0m             device,\n\u001b[1;32m   1322\u001b[0m             dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1323\u001b[0m             non_blocking,\n\u001b[1;32m   1324\u001b[0m             memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format,\n\u001b[1;32m   1325\u001b[0m         )\n\u001b[0;32m-> 1326\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1327\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1328\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1329\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1330\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1331\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m   1332\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e) \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot copy out of meta tensor; no data!\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "Model_MiniLM = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130fc4b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# similarity >= 0.5  \n",
    "def search_closest_by_content_simi_50(content, model, df_emb, df_favorites, filter):\n",
    "\n",
    "        content = re.sub(\"[^A-Za-z]+\", \" \", str(content)).lower()\n",
    "        content = model.encode(content)\n",
    "\n",
    "        # cosine similarity : given embedding VS all embeddings\n",
    "        similarities = cosine_similarity([content], list(df_emb[filter]))[0]\n",
    "\n",
    "        # Store similarity\n",
    "        similarity_df = pd.DataFrame({'uid': df_emb['uid'], 'similarity': similarities})\n",
    "\n",
    "        # filter by similarity\n",
    "        closest = similarity_df[similarity_df['similarity'] >= 0.5].sort_values(by='similarity', ascending=False)\n",
    "\n",
    "        df_merged = df_favorites.merge(closest, left_on='favorites_anime', right_on='uid', how='inner')\n",
    "        grouped_df = df_merged.groupby('profile').agg({'uid': list}).reset_index()\n",
    "\n",
    "        return grouped_df\n",
    "\n",
    "\n",
    "# Top5_similarity  # NOT NEEDED FOR THE APP : \n",
    "def search_closest_by_content_top_5(content, model, df_emb, df_favorites, filter):\n",
    "\n",
    "        content = re.sub(\"[^A-Za-z]+\", \" \", str(content)).lower()\n",
    "        content = model.encode(content)\n",
    "\n",
    "        # cosine similarity : given embedding VS all embeddings\n",
    "        similarities = cosine_similarity([content], list(df_emb[filter]))[0]\n",
    "\n",
    "        # Store similarity\n",
    "        similarity_df = pd.DataFrame({'uid': df_emb['uid'], 'similarity': similarities})\n",
    "\n",
    "        # filter by similarity.\n",
    "        closest = similarity_df.sort_values(by='similarity', ascending=False).head(5)\n",
    "\n",
    "\n",
    "        df_merged = df_favorites.merge(closest, left_on='favorites_anime', right_on='uid', how='inner')\n",
    "        grouped_df = df_merged.groupby('profile').agg({'uid': list}).reset_index()\n",
    "\n",
    "        return grouped_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd65cbd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "2154"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "new_content = \"\"\"Despite being bullied, scorned, and oppressed all of his life, a 34-year-old shut-in still found the resolve to attempt something heroic—only for it to end in a tragic accident. But in a twist of fate, he awakens in another world as Rudeus Greyrat, starting life again as a baby born to two loving parents.\n",
    "\n",
    "Preserving his memories and knowledge from his previous life, Rudeus quickly adapts to his new environment. With the mind of a grown adult, he starts to display magical talent that exceeds all expectations, honing his skill with the help of a mage named Roxy Migurdia. Rudeus learns swordplay from his father, Paul, and meets Sylphiette, a girl his age who quickly becomes his closest friend.\n",
    "\n",
    "As Rudeus' second chance at life begins, he tries to make the most of his new opportunity while conquering his traumatic past. And perhaps, one day, he may find the one thing he could not find in his old world—love.\"\"\"\n",
    "\n",
    "\n",
    "filter = 'synopsis_embedding'\n",
    "df_emb = df_MiniLM\n",
    "df_favorites = df_favorites\n",
    "model = Model_MiniLM\n",
    "\n",
    "# call the function and store in DF   # NOT NEEDED FOR THE APP : \n",
    "Top_5_df = pd.DataFrame(search_closest_by_content_top_5(new_content, model, df_emb, df_favorites, filter))\n",
    "display(Top_5_df.shape[0])\n",
    "\n",
    "\n",
    "# call the function and store in DF\n",
    "simi_50_df = pd.DataFrame(search_closest_by_content_simi_50(new_content, model, df_emb, df_favorites, filter))\n",
    "display(simi_50_df.shape[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7eb831",
   "metadata": {},
   "source": [
    " # jina emb = 1024  (abandonned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4705f9a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lyxor/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/flash_attn/ops/triton/layer_norm.py:985: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
      "  def forward(\n",
      "/home/lyxor/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/flash_attn/ops/triton/layer_norm.py:1044: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
      "  def backward(ctx, dout, *args):\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "Model_jina_1024 = AutoModel.from_pretrained(\"jinaai/jina-embeddings-v3\", trust_remote_code=True).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc122e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get embeddings\n",
    "def get_embeddings(text):\n",
    "    embeddings = model.encode([text], task=\"text-matching\")\n",
    "    return embeddings[0]\n",
    "\n",
    "# Top5_similarity\n",
    "def search_closest_by_content_jina(content, model, df_emb, df_favorites, filter):\n",
    "\n",
    "        content = re.sub(\"[^A-Za-z]+\", \" \", str(content)).lower()\n",
    "        content = get_embeddings(content)\n",
    "\n",
    "        # cosine similarity : given embedding VS all embeddings\n",
    "        similarities = cosine_similarity([content], list(df_emb[filter]))[0]\n",
    "\n",
    "        # Store similarity\n",
    "        similarity_df = pd.DataFrame({'uid': df_emb['uid'], 'similarity': similarities})\n",
    "\n",
    "        # filter by similarity. given_uid exclude\n",
    "        closest = similarity_df.sort_values(by='similarity', ascending=False).head(5)\n",
    "\n",
    "\n",
    "        df_merged = df_favorites.merge(closest, left_on='favorites_anime', right_on='uid', how='inner')\n",
    "        grouped_df = df_merged.groupby('profile').agg({'uid': list}).reset_index()\n",
    "\n",
    "        return grouped_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178da2cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "393"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "filter = 'synopsis_embedding'\n",
    "df_emb = df_jina_1024\n",
    "df_favorites = df_favorites\n",
    "model = Model_jina_1024\n",
    "\n",
    "\n",
    "# call the function and store in DF\n",
    "jina_df = pd.DataFrame(search_closest_by_content_jina(new_content, model, df_emb, df_favorites, filter))\n",
    "display(jina_df.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa40f96",
   "metadata": {},
   "source": [
    "### we will stay on the miniLM embedding, for calculation and standardise with other functions.  Similarity >= 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65f3631",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad278e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATM,  NOT NEEDED FOR THE APP\n",
    "def closest_similarity(target, df, filter):\n",
    "        # cosine similarity : given embedding VS all embeddings\n",
    "        similarities = cosine_similarity([target], list(df[filter]))[0]\n",
    "        similarity_df = pd.DataFrame({'uid': df['uid'], 'similarity': similarities})\n",
    "        similarity_df =  similarity_df.sort_values(by='similarity', ascending=False)\n",
    "\n",
    "        return similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb880c38",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m## début fonction (target, model, df_emb, df_favorites, filter)\u001b[39;00m\n\u001b[1;32m     15\u001b[0m target \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[^A-Za-z]+\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mstr\u001b[39m(target))\u001b[38;5;241m.\u001b[39mlower()\n\u001b[0;32m---> 16\u001b[0m target \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m closest \u001b[38;5;241m=\u001b[39m closest_similarity(target, df_emb, \u001b[38;5;28mfilter\u001b[39m)\n\u001b[1;32m     19\u001b[0m closest\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/sentence_transformers/SentenceTransformer.py:681\u001b[0m, in \u001b[0;36mSentenceTransformer.encode\u001b[0;34m(self, sentences, prompt_name, prompt, batch_size, show_progress_bar, output_value, precision, convert_to_numpy, convert_to_tensor, device, normalize_embeddings, **kwargs)\u001b[0m\n\u001b[1;32m    672\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m features:\n\u001b[1;32m    673\u001b[0m             features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(\n\u001b[1;32m    674\u001b[0m                 (\n\u001b[1;32m    675\u001b[0m                     features[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken_type_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    678\u001b[0m                 \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m    679\u001b[0m             )\n\u001b[0;32m--> 681\u001b[0m features \u001b[38;5;241m=\u001b[39m \u001b[43mbatch_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    682\u001b[0m features\u001b[38;5;241m.\u001b[39mupdate(extra_features)\n\u001b[1;32m    684\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n",
      "File \u001b[0;32m~/miniconda3/envs/DeepLearn/lib/python3.10/site-packages/sentence_transformers/util.py:1209\u001b[0m, in \u001b[0;36mbatch_to_device\u001b[0;34m(batch, target_device)\u001b[0m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(batch[key], Tensor):\n\u001b[0;32m-> 1209\u001b[0m         batch[key] \u001b[38;5;241m=\u001b[39m \u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_device\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m batch\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: unspecified launch failure\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# ATM,  NOT NEEDED FOR THE APP\n",
    "\n",
    "new_content = \"\"\"Despite being bullied, scorned, and oppressed all of his life, a 34-year-old shut-in still found the resolve to attempt something heroic—only for it to end in a tragic accident. But in a twist of fate, he awakens in another world as Rudeus Greyrat, starting life again as a baby born to two loving parents.\n",
    "\n",
    "Preserving his memories and knowledge from his previous life, Rudeus quickly adapts to his new environment. With the mind of a grown adult, he starts to display magical talent that exceeds all expectations, honing his skill with the help of a mage named Roxy Migurdia. Rudeus learns swordplay from his father, Paul, and meets Sylphiette, a girl his age who quickly becomes his closest friend.\n",
    "\n",
    "As Rudeus' second chance at life begins, he tries to make the most of his new opportunity while conquering his traumatic past. And perhaps, one day, he may find the one thing he could not find in his old world—love.\"\"\"\n",
    "\n",
    "MiniLM = SentenceTransformer(\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "filter = 'synopsis_embedding'\n",
    "\n",
    "def generate_diffusion_list(target, model, df_emb, df_favorites, filter):\n",
    "\n",
    "    target = re.sub(\"[^A-Za-z]+\", \" \", str(target)).lower()\n",
    "    target = model.encode(target)\n",
    "\n",
    "    closest = closest_similarity(target, df_emb, filter)\n",
    "\n",
    "    df_merged = df_favorites.merge(closest[closest['similarity'] >= 0.5], left_on='favorites_anime', right_on='uid', how='inner')\n",
    "    grouped_df = df_merged.groupby('profile').agg({'uid': list}).reset_index()\n",
    "\n",
    "    return grouped_df\n",
    "\n",
    "diffusion_df = generate_diffusion_list(new_content, MiniLM, df_MiniLM, df_favorites, filter)\n",
    "diffusion_df.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
